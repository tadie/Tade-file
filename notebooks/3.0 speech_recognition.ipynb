{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3.0 speech_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kAT68JRAhDPe",
        "x2AUYq5FhDPk",
        "KnWmRfauhDPl",
        "Pdn6jGfQhDPt",
        "T2QuYGjBzeyO",
        "wG-rOaJehDP0",
        "ZZlX4X15hDP1",
        "CX_g8ub8hDP2",
        "XdbPWrohu1hM"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "49f7819295bc3ae529ffe0a7be621f3fbca93eb1b35a02d2e68894336497ab44"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit ('env': venv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tadie/Tade-file/blob/main/notebooks/3.0%20speech_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech Recognition\n"
      ],
      "metadata": {
        "id": "u4ipLfMihDPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_ux7rFCDhDPY",
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('No GPU.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 17 07:27:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ0ZNj-Og8zJ",
        "outputId": "fc01a09f-068b-418a-ab62-6b5cb2307917"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 18167328350589874552\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14415560704\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 15263938289212951000\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl-74Q2Dg8zJ",
        "outputId": "220e2522-c5af-43d4-f831-ccc7d8375e97"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import pickle\n",
        "\n",
        "import librosa\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.io as pio\n",
        "\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "import plotly.graph_objects as go\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "\n",
        "import IPython.display as ipd\n",
        "from wordcloud import WordCloud\n",
        "import plotly.express as px\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import librosa.display\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pickle\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "f5ab6fjJhDPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "from logging.handlers import TimedRotatingFileHandler\n",
        "FORMATTER = logging.Formatter(\n",
        "    \"%(asctime)s — %(name)s — %(levelname)s — %(message)s\")\n",
        "LOG_FILE = \"my_app.log\"\n",
        "\n",
        "\n",
        "def get_console_handler():\n",
        "    console_handler = logging.StreamHandler(sys.stdout)\n",
        "    console_handler.setFormatter(FORMATTER)\n",
        "    return console_handler\n",
        "\n",
        "\n",
        "def get_file_handler():\n",
        "    file_handler = TimedRotatingFileHandler(LOG_FILE, when='midnight')\n",
        "    file_handler.setFormatter(FORMATTER)\n",
        "    return file_handler\n",
        "\n",
        "\n",
        "def get_logger(logger_name):\n",
        "    logger = logging.getLogger(logger_name)\n",
        "    # better to have too much log than not enough\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    logger.addHandler(get_console_handler())\n",
        "    logger.addHandler(get_file_handler())\n",
        "    # with this pattern, it's rarely necessary to propagate the error up to parent\n",
        "    logger.propagate = False\n",
        "    return logger\n",
        "\n",
        "\n",
        "def get_logger(logger_name):\n",
        "    logger = logging.getLogger(logger_name)\n",
        "    # better to have too much log than not enough\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    logger.addHandler(get_console_handler())\n",
        "    logger.addHandler(get_file_handler())\n",
        "    # with this pattern, it's rarely necessary to propagate the error up to parent\n",
        "    logger.propagate = False\n",
        "    return logger"
      ],
      "metadata": {
        "id": "udIGGUdF5cBV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "get_logger\n",
        "class AudioVis():\n",
        "  \"\"\"Visualisation of the audio file, spectogram, mfcc....\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.logger = get_logger(\"FileHandler\")\n",
        "\n",
        "  def play_audio(self, samples, sr=22000):\n",
        "    return ipd.Audio(samples, rate=sr)\n",
        "\n",
        "  def wav_plot(self, signal, title, x_label, y_label, sr=22000):\n",
        "    plt.figure(figsize=(25, 5))\n",
        "    librosa.display.waveplot(signal, sr=sr)\n",
        "    plt.title(title)\n",
        "    plt.ylabel(x_label)\n",
        "    plt.xlabel(y_label)\n",
        "    plt.show()\n",
        "\n",
        "  def get_wc(self, df, column, stop_words):\n",
        "    plt.figure(figsize=(30, 20))\n",
        "    wordcloud = WordCloud(font_path='../fonts/NotoSansEthiopic-Medium.ttf', max_words=5000,\n",
        "                          background_color=\"salmon\", width=3000, height=2000, colormap='Pastel1',\n",
        "                          collocations=False, stopwords=stop_words).generate(' '.join(df[column].values))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis('off')\n",
        "    plt.title('Most Frequent Words In Amharic Audio Transcription', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "  def plot_raw_audio(vis_raw_audio, title='Audio Signal', size=(12, 3)):\n",
        "    fig = plt.figure(figsize=size)\n",
        "    ax = fig.add_subplot(111)\n",
        "    steps = len(vis_raw_audio)\n",
        "    ax.plot(np.linspace(1, steps, steps), vis_raw_audio)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.show()\n",
        "\n",
        "  def plot_mfcc_feature(self, vis_mfcc_feature):\n",
        "    fig = plt.figure(figsize=(12, 5))\n",
        "    ax = fig.add_subplot(111)\n",
        "    im = ax.imshow(vis_mfcc_feature, cmap=plt.cm.jet, aspect='auto')\n",
        "    plt.title('Normalized MFCC')\n",
        "    plt.ylabel('Time')\n",
        "    plt.xlabel('MFCC Coefficient')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "    ax.set_xticks(np.arange(0, 13, 2), minor=False)\n",
        "    plt.show()\n",
        "\n",
        "  def plot_spectrogram_feature(self, vis_spectrogram_feature):\n",
        "    fig = plt.figure(figsize=(12, 5))\n",
        "    ax = fig.add_subplot(111)\n",
        "    im = ax.imshow(vis_spectrogram_feature, cmap=plt.cm.jet, aspect='auto')\n",
        "    plt.title('Normalized Spectrogram')\n",
        "    plt.ylabel('Time')\n",
        "    plt.xlabel('Frequency')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "U_8BXIO27FlO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_logger\n",
        "class CleanAudio():\n",
        "  \"\"\"Clean audio data by removing dead spaces, ...\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.logger = get_logger(\"CleanAudio\")\n",
        "\n",
        "  def normalize_audio(self, signal):\n",
        "    feats_mean = np.mean(signal, axis=0)\n",
        "    feats_std = np.std(signal, axis=0)\n",
        "    signal = (signal - feats_mean) / (feats_std + 1e-14)\n",
        "    return signal\n",
        "\n",
        "  def trim_audio(self, signal, trim_db=None):\n",
        "    signal, index = librosa.effects.trim(signal, top_db=trim_db)\n",
        "    return signal\n",
        "\n",
        "  def split_audio(self, signal, clean_db=None):\n",
        "    yt = librosa.effects.split(signal, top_db=clean_db)\n",
        "    cleaned_signal = []\n",
        "    for start_i, end_i in yt:\n",
        "      cleaned_signal.append(signal[start_i: end_i])\n",
        "    signal = np.concatenate(np.array(cleaned_signal), axis=0)\n",
        "    return signal"
      ],
      "metadata": {
        "id": "i1ChbZRh76Xc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "  RANDOM_SEED = 27\n",
        "  ASSETS_PATH = Path(\"../\")\n",
        "  REPO = \"https://github.com/10acad-group3/speechTotext\"\n",
        "  DATASET_PATH = ASSETS_PATH / \"data\"\n",
        "  FEATURES_PATH = ASSETS_PATH / \"features\"\n",
        "  MODELS_PATH = ASSETS_PATH / \"models\"\n",
        "  METRICS_FILE_PATH = ASSETS_PATH / \"metrics\"\n",
        "  IMAGE_PATH = ASSETS_PATH / \"img\""
      ],
      "metadata": {
        "id": "W2ZqsW9v8uJX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import pickle\n",
        "Config\n",
        "get_logger\n",
        "from tqdm import tqdm\n",
        "CleanAudio\n",
        "\n",
        "\n",
        "PATH_TRAIN_WAV = \"/content/drive/MyDrive/data/AMHARIC/train/wav/\"\n",
        "PATH_TEST_WAV = \"/content/drive/MyDrive/data/AMHARIC/test/wav/\"\n",
        "CLEAN_PATH_TRAIN_WAV = \"/content/drive/MyDrive/data/AMHARIC_CLEAN/train/wav/\"\n",
        "CLEAN_PATH_TEST_WAV = \"/content/drive/MyDrive/data/AMHARIC_CLEAN/test/wav/\"\n",
        "\n",
        "\n",
        "class FileHandler():\n",
        "  \"\"\"Read audio, audio transcription, Save cleaned Audio and transcriptions\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.logger = get_logger(\"FileHandler\")\n",
        "    self.clean_audio = CleanAudio()\n",
        "\n",
        "  def save_csv(self, df, csv_path, index=False):\n",
        "    try:\n",
        "      df.to_csv(csv_path, index=index)\n",
        "      self.logger.info(\"file saved as csv\")\n",
        "\n",
        "    except Exception:\n",
        "      self.logger.exception(\"save failed\")\n",
        "\n",
        "  def read_csv(self, csv_path, missing_values=[]):\n",
        "    try:\n",
        "      df = pd.read_csv(csv_path, na_values=missing_values)\n",
        "      self.logger.debug(\"file read as csv\")\n",
        "      return df\n",
        "    except FileNotFoundError:\n",
        "      self.logger.exception(\"file not found\")\n",
        "\n",
        "  def read_text(self, text_path):\n",
        "    text = []\n",
        "    with open(text_path) as fp:\n",
        "      line = fp.readline()\n",
        "      while line:\n",
        "        text.append(line)\n",
        "        line = fp.readline()\n",
        "    return text\n",
        "\n",
        "  def read_data(self, PATH_TRAIN_TEXT, PATH_TEST_TEXT, train_labels, test_labels):\n",
        "    train_text = self.read_text(PATH_TRAIN_TEXT)\n",
        "    test_text = self.read_text(PATH_TEST_TEXT)\n",
        "\n",
        "    train_text.extend(test_text)\n",
        "    train_labels.extend(test_labels)\n",
        "\n",
        "    new_text = []\n",
        "    new_labels = []\n",
        "    for i in train_text:\n",
        "      result = i.split()\n",
        "\n",
        "      if result[0] in train_labels:  # if the audio file exists\n",
        "        new_text.append(' '.join([elem for elem in result[1:]]))\n",
        "        new_labels.append(result[0])\n",
        "\n",
        "    return new_text, new_labels\n",
        "\n",
        "  def read_audio_signal(self, audio_file_loc, sr=22000):\n",
        "    samples, sample_rate = librosa.load(audio_file_loc, sr=sr)\n",
        "    return (samples, sample_rate)\n",
        "\n",
        "  def save_audio_as_numpy(self, df, sr):\n",
        "    inFiles = []\n",
        "    outFiles = []\n",
        "    for index, row in df.iterrows():\n",
        "      if(row[\"category\"] == \"Train\"):\n",
        "        inFiles.append(PATH_TRAIN_WAV + row[\"key\"] + \".wav\")\n",
        "        outFiles.append(CLEAN_PATH_TRAIN_WAV + row[\"key\"] + \".npy\")\n",
        "      else:\n",
        "        inFiles.append(PATH_TEST_WAV + row[\"key\"] + \".wav\")\n",
        "        outFiles.append(CLEAN_PATH_TEST_WAV + row[\"key\"] + \".npy\")\n",
        "\n",
        "    for in_file, out_file in zip(tqdm(inFiles), tqdm(outFiles)):\n",
        "      try:\n",
        "        wav, rate = librosa.load(in_file, sr=None)\n",
        "        y = librosa.resample(wav, rate, sr)\n",
        "\n",
        "        y = self.clean_audio.normalize_audio(y)\n",
        "        y = self.clean_audio.split_audio(y, 30)\n",
        "\n",
        "        np.save(out_file, y)\n",
        "\n",
        "      except EOFError as e:\n",
        "        self.logger = get_logger(\"Failed to save audio \\n\" + e)"
      ],
      "metadata": {
        "id": "d-5AEch18x3d"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogMelgramLayer(Layer):\n",
        "  def __init__(self, num_fft, hop_length, num_mels, sample_rate, f_min, f_max, eps, **kwargs):\n",
        "    super(LogMelgramLayer, self).__init__(**kwargs)\n",
        "\n",
        "    self.num_fft = num_fft\n",
        "    self.hop_length = hop_length\n",
        "    self.num_mels = num_mels\n",
        "    self.sample_rate = sample_rate\n",
        "    self.f_min = f_min\n",
        "    self.f_max = f_max\n",
        "    self.eps = eps\n",
        "    self.num_freqs = num_fft // 2 + 1\n",
        "    lin_to_mel_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "        num_mel_bins=self.num_mels,\n",
        "        num_spectrogram_bins=self.num_freqs,\n",
        "        sample_rate=self.sample_rate,\n",
        "        lower_edge_hertz=self.f_min,\n",
        "        upper_edge_hertz=self.f_max,\n",
        "    )\n",
        "\n",
        "    self.lin_to_mel_matrix = lin_to_mel_matrix\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.non_trainable_weights.append(self.lin_to_mel_matrix)\n",
        "    super(LogMelgramLayer, self).build(input_shape)\n",
        "\n",
        "  def call(self, input):\n",
        "\n",
        "    def _tf_log10(x):\n",
        "      numerator = tf.math.log(x)\n",
        "      denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
        "      return numerator / denominator\n",
        "\n",
        "    stfts = tf.signal.stft(\n",
        "        input,\n",
        "        frame_length=self.num_fft,\n",
        "        frame_step=self.hop_length,\n",
        "        pad_end=False,  # librosa test compatibility\n",
        "    )\n",
        "    mag_stfts = tf.abs(stfts)\n",
        "\n",
        "    melgrams = tf.tensordot(  # assuming channel_first, so (b, c, f, t)\n",
        "        tf.square(mag_stfts), self.lin_to_mel_matrix, axes=[2, 0]\n",
        "    )\n",
        "    log_melgrams = _tf_log10(melgrams + self.eps)\n",
        "    return tf.expand_dims(log_melgrams, 3)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'num_fft': self.num_fft,\n",
        "        'hop_length': self.hop_length,\n",
        "        'num_mels': self.num_mels,\n",
        "        'sample_rate': self.sample_rate,\n",
        "        'f_min': self.f_min,\n",
        "        'f_max': self.f_max,\n",
        "        'eps': self.eps,\n",
        "    }\n",
        "    base_config = super(LogMelgramLayer, self).get_config()\n",
        "    return dict(list(config.items()) + list(base_config.items()))"
      ],
      "metadata": {
        "id": "_DiNxMDf9n9q"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "source": [
        "sns.set()\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option(\"expand_frame_repr\", False)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "sys.path.append(os.path.abspath(os.path.join('../scripts')))"
      ],
      "outputs": [],
      "metadata": {
        "id": "XU3Fv63chDPZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "source": [
        "clean_audio = CleanAudio()\n",
        "file_handler = FileHandler()\n",
        "audio_vis = AudioVis()"
      ],
      "outputs": [],
      "metadata": {
        "id": "jYInuJjghDPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n"
      ],
      "metadata": {
        "id": "mTqSkwMhhDPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "source": [
        "# # Vs Code\n",
        "# PATH_Model = \"../models/\"\n",
        "# PATH_IMG = \"../img/\"\n",
        "\n",
        "PATH_Model = \"/content/drive/MyDrive/PATH_Model/\"\n",
        "PATH_IMG = \"/content/drive/MyDrive/imgs/\"\n",
        "PATH_TRAIN_WAV = \"/content/drive/MyDrive/data/AMHARIC_CLEAN/train/wav/\"\n",
        "PATH_TEST_WAV = \"/content/drive/MyDrive/data/AMHARIC_CLEAN/test/wav/\"\n",
        "data = pd.read_csv('/content/drive/MyDrive/data/clean_data.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "lamucPibhDPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "source": [
        "data.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                key                                                                 text  char_length  duration  speed category\n",
              "0           0  tr_10000_tr097082  የተለያዩ የትግራይ አውራጃ ተወላጆች ገንዘባቸውን አዋጥተው የልማት ተቋማትን እንዲመሰርቱ ትልማ አይፈቅድ ም           67      7.42   9.02    Train\n",
              "1           1  tr_10001_tr097083                                 የጠመንጃ ተኩስ ተከፈተና አራት የኤርትራ ወታደሮች ተገደሉ           36      4.67   7.71    Train\n",
              "2           2  tr_10002_tr097084                                       ላነሷቸው ጥያቄዎች የሰጡትን መልስ አቅርበ ነዋል           30      4.67   6.42    Train\n",
              "3           3  tr_10003_tr097085                               እብዱ አስፋልቱ ላይየ ኰለኰ ለው ድንጋይ መኪና አላሳልፍ አለ           38      4.42   8.61    Train\n",
              "4           4  tr_10004_tr097086                                  ጠጁን ኰ መኰ መ ኰ መኰ መና ሚስቱን ሲ ያሰቃያት አደረ           35      4.22   8.29    Train"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7e6749d-75b2-4948-98a2-e8fb52e544e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>key</th>\n",
              "      <th>text</th>\n",
              "      <th>char_length</th>\n",
              "      <th>duration</th>\n",
              "      <th>speed</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tr_10000_tr097082</td>\n",
              "      <td>የተለያዩ የትግራይ አውራጃ ተወላጆች ገንዘባቸውን አዋጥተው የልማት ተቋማትን እንዲመሰርቱ ትልማ አይፈቅድ ም</td>\n",
              "      <td>67</td>\n",
              "      <td>7.42</td>\n",
              "      <td>9.02</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>tr_10001_tr097083</td>\n",
              "      <td>የጠመንጃ ተኩስ ተከፈተና አራት የኤርትራ ወታደሮች ተገደሉ</td>\n",
              "      <td>36</td>\n",
              "      <td>4.67</td>\n",
              "      <td>7.71</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>tr_10002_tr097084</td>\n",
              "      <td>ላነሷቸው ጥያቄዎች የሰጡትን መልስ አቅርበ ነዋል</td>\n",
              "      <td>30</td>\n",
              "      <td>4.67</td>\n",
              "      <td>6.42</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>tr_10003_tr097085</td>\n",
              "      <td>እብዱ አስፋልቱ ላይየ ኰለኰ ለው ድንጋይ መኪና አላሳልፍ አለ</td>\n",
              "      <td>38</td>\n",
              "      <td>4.42</td>\n",
              "      <td>8.61</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>tr_10004_tr097086</td>\n",
              "      <td>ጠጁን ኰ መኰ መ ኰ መኰ መና ሚስቱን ሲ ያሰቃያት አደረ</td>\n",
              "      <td>35</td>\n",
              "      <td>4.22</td>\n",
              "      <td>8.29</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7e6749d-75b2-4948-98a2-e8fb52e544e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7e6749d-75b2-4948-98a2-e8fb52e544e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7e6749d-75b2-4948-98a2-e8fb52e544e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "wFTnA1TJizBG",
        "outputId": "13c964c8-2f77-4d26-a1d5-e6be6e97680d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "source": [
        "def get_paths(df):\n",
        "  paths = []\n",
        "  for col, row in df.iterrows():\n",
        "    if(row[\"category\"] == \"Train\"):\n",
        "      paths.append(PATH_TRAIN_WAV + row[\"key\"] + \".npy\")\n",
        "    else:\n",
        "      paths.append(PATH_TEST_WAV + row[\"key\"] + \".npy\")\n",
        "\n",
        "  return paths"
      ],
      "outputs": [],
      "metadata": {
        "id": "p3H9PPrvhDPd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "source": [
        "data[\"path\"] = get_paths(data)\n",
        "data.sort_values(by=[\"duration\"], inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data = data[[\"text\", \"char_length\", \"duration\", \"path\"]]\n",
        "data[[\"text\", \"char_length\", \"duration\"]]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                          text  char_length  duration\n",
              "0                                                                                                                ሼራተን አዲስ ተመረቀ           13      2.05\n",
              "1                                                                                                               ፖሊሱ እስረኞቹን ቆጠረ           14      2.05\n",
              "2                                                                                                            ይህ ቀስ በቀስ እያደገ ሄደ           17      2.05\n",
              "3                                                                                                            ኢነጋማ ህጋዊ እውቅና አገኘ           17      2.05\n",
              "4                                                                                                         በተጨባጭ ስና የው ግን ባዶ ነው           20      2.05\n",
              "...                                                                                                                        ...          ...       ...\n",
              "10669                       ቦናፓርቲ ያዊ ያልሆኑ ብዛት ያላቸው ጸረ ህዝብ መንግስታት በጸረ ዴሞከራሲ ና በሙስና ውስጥ ሲዘፈቁ እንደሚታዩ ለማወቅ ትንሽ አስተውሎት ን ነው የሚ ጠይቀው           98     13.95\n",
              "10670                                ከዚህ እጅግዘመናዊ ና ውድ ሰአት ሽያጭ ትርፍ ሶስት በመቶ በቋሚነት ሳኦ ክሪስቶ ቮል ፋውንዴሽን ለተባለው የሮናልዶ የእርዳታ ድርጅት ይው ላል           89     13.95\n",
              "10671                                   ይልቁንም በተለመደው አኳኋን ከሚኒስትሩ በታች መሆን ያለበት ኤታማዦር ሹም በቀጥታ ሪፖርት የሚያደርገውና ተጠሪነቱ ለጠቅላይ ሚኒስትሩ ነው           86     13.95\n",
              "10672  ፕሮጀክቱን ለማዘጋጀትና ለማቀነባበር እንዲሁም ጥናቱና ዲዛይኑን ተግባራዊ ለማድረግ እንዲቻል ከሶስቱም ሀገሮች የተውጣጡ ባለሙያዎች ያሉት የፕሮጀክት ጽፈት ቤት እንደሚኖርም ሚኒስትሩ ገልጸዋል          119     13.95\n",
              "10673                                    ከዚያም ቀድሞ የተማሩበት የሀንጋሪ ው ኮሌጅ ወደ ዩንቨርስቲ ነት በመቀየሩ ወደዚያው በመጓዝ የፒኤችዲ ዶክትሬት ዲግሪያቸውን ተቀብለ ዋል           85     13.95\n",
              "\n",
              "[10674 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72a730be-a5ce-4da7-b305-3fab15d184d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>char_length</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ሼራተን አዲስ ተመረቀ</td>\n",
              "      <td>13</td>\n",
              "      <td>2.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ፖሊሱ እስረኞቹን ቆጠረ</td>\n",
              "      <td>14</td>\n",
              "      <td>2.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ይህ ቀስ በቀስ እያደገ ሄደ</td>\n",
              "      <td>17</td>\n",
              "      <td>2.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ኢነጋማ ህጋዊ እውቅና አገኘ</td>\n",
              "      <td>17</td>\n",
              "      <td>2.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>በተጨባጭ ስና የው ግን ባዶ ነው</td>\n",
              "      <td>20</td>\n",
              "      <td>2.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10669</th>\n",
              "      <td>ቦናፓርቲ ያዊ ያልሆኑ ብዛት ያላቸው ጸረ ህዝብ መንግስታት በጸረ ዴሞከራሲ ና በሙስና ውስጥ ሲዘፈቁ እንደሚታዩ ለማወቅ ትንሽ አስተውሎት ን ነው የሚ ጠይቀው</td>\n",
              "      <td>98</td>\n",
              "      <td>13.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10670</th>\n",
              "      <td>ከዚህ እጅግዘመናዊ ና ውድ ሰአት ሽያጭ ትርፍ ሶስት በመቶ በቋሚነት ሳኦ ክሪስቶ ቮል ፋውንዴሽን ለተባለው የሮናልዶ የእርዳታ ድርጅት ይው ላል</td>\n",
              "      <td>89</td>\n",
              "      <td>13.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10671</th>\n",
              "      <td>ይልቁንም በተለመደው አኳኋን ከሚኒስትሩ በታች መሆን ያለበት ኤታማዦር ሹም በቀጥታ ሪፖርት የሚያደርገውና ተጠሪነቱ ለጠቅላይ ሚኒስትሩ ነው</td>\n",
              "      <td>86</td>\n",
              "      <td>13.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10672</th>\n",
              "      <td>ፕሮጀክቱን ለማዘጋጀትና ለማቀነባበር እንዲሁም ጥናቱና ዲዛይኑን ተግባራዊ ለማድረግ እንዲቻል ከሶስቱም ሀገሮች የተውጣጡ ባለሙያዎች ያሉት የፕሮጀክት ጽፈት ቤት እንደሚኖርም ሚኒስትሩ ገልጸዋል</td>\n",
              "      <td>119</td>\n",
              "      <td>13.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10673</th>\n",
              "      <td>ከዚያም ቀድሞ የተማሩበት የሀንጋሪ ው ኮሌጅ ወደ ዩንቨርስቲ ነት በመቀየሩ ወደዚያው በመጓዝ የፒኤችዲ ዶክትሬት ዲግሪያቸውን ተቀብለ ዋል</td>\n",
              "      <td>85</td>\n",
              "      <td>13.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10674 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72a730be-a5ce-4da7-b305-3fab15d184d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72a730be-a5ce-4da7-b305-3fab15d184d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72a730be-a5ce-4da7-b305-3fab15d184d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "edCip8fehDPd",
        "outputId": "30a59da0-5a1e-4c72-c488-3f896ee57eb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "kAT68JRAhDPe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "source": [
        "class TokenizerWrap(Tokenizer):\n",
        "    def __init__(self, texts, padding, len_sent, filters, reverse=False):\n",
        "        Tokenizer.__init__(self, filters=filters, char_level=True)\n",
        "\n",
        "        self.len_sent = len_sent\n",
        "        self.fit_on_texts(texts)\n",
        "\n",
        "        self.index_to_word = dict(zip(self.word_index.values(), self.word_index.keys()))\n",
        "        self.tokens = self.texts_to_sequences(texts)\n",
        "\n",
        "        if reverse:\n",
        "            self.tokens = [list(reversed(x)) for x in self.tokens]\n",
        "            truncating = 'pre'\n",
        "        else:\n",
        "            truncating = 'post'\n",
        "\n",
        "        self.tokens_padded = pad_sequences(self.tokens,\n",
        "                                           maxlen=len_sent,\n",
        "                                           padding=padding,\n",
        "                                           truncating=truncating\n",
        "                                           )\n",
        "\n",
        "    def token_to_word(self, token):\n",
        "        word = \" \" if token == 0 else self.index_to_word[token]\n",
        "        return word\n",
        "\n",
        "    def tokens_to_string(self, tokens):\n",
        "        words = [self.index_to_word[token] for token in tokens if token != 0]\n",
        "        text = \"\".join(words)\n",
        "        return text\n",
        "\n",
        "    def text_to_tokens(self, text, reverse=False, padding=False):\n",
        "        tokens = self.texts_to_sequences([text])\n",
        "        tokens = np.array(tokens)\n",
        "\n",
        "        if reverse:\n",
        "            tokens = np.flip(tokens, axis=1)\n",
        "            truncating = 'pre'\n",
        "        else:\n",
        "            truncating = 'post'\n",
        "\n",
        "        if padding:\n",
        "            tokens = pad_sequences(tokens,\n",
        "                                   maxlen=self.len_sent,\n",
        "                                   padding=truncating,\n",
        "                                   truncating=truncating\n",
        "                                   )\n",
        "        return tokens\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "_9M9R7uGhDPe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "source": [
        "MAX_SENTENCE_LENGTH = 125       # The longest sentence in the data is around 150 chars\n",
        "filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n።”፤፦’፥'  # { ።”፤፦’፥' } unique for amharic"
      ],
      "outputs": [],
      "metadata": {
        "id": "m68LsfCzhDPf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "source": [
        "%%time\n",
        "tokenizer = TokenizerWrap(texts=data.text,\n",
        "                          padding='post',\n",
        "                          reverse=False,\n",
        "                          len_sent=MAX_SENTENCE_LENGTH,\n",
        "                          filters=filters)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 399 ms, sys: 3.69 ms, total: 403 ms\n",
            "Wall time: 405 ms\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjQqp2bthDPf",
        "outputId": "3504e667-226a-43f8-ff7c-115953deb82b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "source": [
        "print(len(tokenizer.word_index))\n",
        "print(tokenizer.word_index)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "222\n",
            "{' ': 1, 'ን': 2, 'ት': 3, 'ው': 4, 'ስ': 5, 'ያ': 6, 'የ': 7, 'ተ': 8, 'በ': 9, 'አ': 10, 'ል': 11, 'እ': 12, 'ለ': 13, 'ር': 14, 'መ': 15, 'ም': 16, 'ች': 17, 'ና': 18, 'ደ': 19, 'ነ': 20, 'ገ': 21, 'ማ': 22, 'ባ': 23, 'ይ': 24, 'ሚ': 25, 'ግ': 26, 'ራ': 27, 'ቸ': 28, 'ላ': 29, 'ብ': 30, 'ድ': 31, 'ረ': 32, 'ሰ': 33, 'ከ': 34, 'ወ': 35, 'ኢ': 36, 'ታ': 37, 'ዳ': 38, 'ክ': 39, 'ዮ': 40, 'ዋ': 41, 'ህ': 42, 'ጵ': 43, 'ጥ': 44, 'ቀ': 45, 'ሪ': 46, 'ጠ': 47, 'ቅ': 48, 'ዲ': 49, 'ሳ': 50, 'ዎ': 51, 'ሮ': 52, 'ሩ': 53, 'ሉ': 54, 'ሆ': 55, 'ሁ': 56, 'ጋ': 57, 'ሊ': 58, 'ቶ': 59, 'ካ': 60, 'ፈ': 61, 'ጣ': 62, 'ፍ': 63, 'ሀ': 64, 'ሞ': 65, 'ሽ': 66, 'ዊ': 67, 'ዘ': 68, 'ቱ': 69, 'ሬ': 70, 'ኤ': 71, 'ኮ': 72, 'ሎ': 73, 'ኛ': 74, 'ዛ': 75, 'ሲ': 76, 'ቃ': 77, 'ጉ': 78, 'ቡ': 79, 'ቻ': 80, 'ዝ': 81, 'ፕ': 82, 'ቢ': 83, 'ዚ': 84, 'ኑ': 85, 'ሙ': 86, 'ሶ': 87, 'ጀ': 88, 'ቁ': 89, 'ኖ': 90, 'ኩ': 91, 'ቋ': 92, 'ሌ': 93, 'ቤ': 94, 'ሱ': 95, 'ኒ': 96, 'ቹ': 97, 'ኝ': 98, 'ጸ': 99, 'ዱ': 100, 'ቲ': 101, 'ጅ': 102, 'ሸ': 103, 'ዜ': 104, 'ቴ': 105, 'ቆ': 106, 'ዙ': 107, 'ዴ': 108, 'ኔ': 109, 'ጡ': 110, 'ኙ': 111, 'ፋ': 112, 'ዶ': 113, 'ጐ': 114, 'ጫ': 115, 'ፊ': 116, 'ጽ': 117, 'ጃ': 118, 'ጊ': 119, 'ጻ': 120, 'ኞ': 121, 'ሄ': 122, 'ጨ': 123, 'ቦ': 124, 'ሴ': 125, 'ዩ': 126, 'ኦ': 127, 'ፖ': 128, 'ሻ': 129, 'ሜ': 130, 'ፓ': 131, 'ጭ': 132, 'ኳ': 133, 'ኘ': 134, 'ቷ': 135, 'ጂ': 136, 'ጓ': 137, 'ቂ': 138, 'ፌ': 139, 'ፉ': 140, 'ኬ': 141, 'ኪ': 142, 'ጦ': 143, 'ዬ': 144, 'ሏ': 145, 'ሺ': 146, 'ፒ': 147, 'ፎ': 148, 'ጆ': 149, 'ሂ': 150, 'ቾ': 151, 'ቨ': 152, 'ጹ': 153, 'ሟ': 154, 'ጤ': 155, 'ሹ': 156, 'ጮ': 157, 'ዞ': 158, 'ቄ': 159, 'ጪ': 160, 'ሯ': 161, 'ኗ': 162, 'ኋ': 163, 'ጄ': 164, 'ቧ': 165, 'ሷ': 166, 'ኡ': 167, 'ሾ': 168, 'ጿ': 169, 'ቪ': 170, 'ጁ': 171, 'ኰ': 172, 'ፏ': 173, 'ዥ': 174, 'ጳ': 175, 'ጌ': 176, 'ጧ': 177, 'ፐ': 178, 'ኸ': 179, 'ፔ': 180, 'ቬ': 181, 'ዷ': 182, 'ዪ': 183, 'ቼ': 184, 'ቺ': 185, 'ጩ': 186, 'ዟ': 187, 'ሼ': 188, 'ቫ': 189, 'ዤ': 190, 'ዌ': 191, 'ጾ': 192, 'ቭ': 193, 'ኟ': 194, 'ሿ': 195, 'ጼ': 196, 'ኜ': 197, 'ጬ': 198, 'ዢ': 199, 'ጯ': 200, 'ጺ': 201, 'ፑ': 202, 'ጶ': 203, 'ዡ': 204, 'ጢ': 205, 'ኚ': 206, 'ቿ': 207, 'ጇ': 208, 'ጴ': 209, 'ዉ': 210, 'ጰ': 211, 'ዧ': 212, 'ጔ': 213, 'ዣ': 214, 'ዦ': 215, 'ዠ': 216, 'ቩ': 217, 'ቮ': 218, 'ኲ': 219, 'ጲ': 220, 'ጱ': 221, 'ቯ': 222}\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aOmYppXhDPg",
        "outputId": "97579481-fa9f-46aa-e76b-46ef5b4c968c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "source": [
        "data.text[1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ፖሊሱ እስረኞቹን ቆጠረ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ot8U7WOChDPh",
        "outputId": "e289adcf-e17a-44e8-8097-8a8a7816aa1f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "source": [
        "sample = tokenizer.text_to_tokens(data.text[1], padding=True)\n",
        "sample"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[128,  58,  95,   1,  12,   5,  32, 121,  97,   2,   1, 106,  47,\n",
              "         32,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpgQu66vhDPi",
        "outputId": "9345e1d4-ae79-441f-9683-9edcf0ba064b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "source": [
        "print(tokenizer.tokens_to_string(sample[0]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ፖሊሱ እስረኞቹን ቆጠረ\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LVLSRKjhDPj",
        "outputId": "895540fc-4779-4f19-a0a5-aae3d99db857"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "save token"
      ],
      "metadata": {
        "id": "TFA9TQzrhDPj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "source": [
        "with open( str(PATH_Model + 'char_tokenizer_amharic.pickle'), 'wb') as handle:\n",
        "  pickle.dump(tokenizer, handle)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "PicklingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-c2eb281846c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_Model\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'char_tokenizer_amharic.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.TokenizerWrap'>: it's not the same object as __main__.TokenizerWrap"
          ]
        }
      ],
      "metadata": {
        "id": "F_qGS_kPhDPk",
        "outputId": "2c2f986d-f96c-4a6f-ee2a-c750535cdbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "x2AUYq5FhDPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can do data augmentation on the raw audio signal by changing the Pitch or Audio Speed and adding noise by a random amount. Data augmentation adds more variety to our input data and helps the model to generalize on a wider range of inputs."
      ],
      "metadata": {
        "id": "mrLdt7F01JP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "source": [
        "class AudioAugment():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "   \n",
        "  def change_speed(self, data):\n",
        "    speed_rate = np.random.uniform(0.8, 1.2)\n",
        "    wav_speed_tune = cv2.resize(data, (1, int(len(data) * speed_rate))).squeeze()\n",
        "\n",
        "    if len(wav_speed_tune) < len(data):\n",
        "      padding = len(data) - len(wav_speed_tune)\n",
        "      offset = padding // 2\n",
        "      wav_speed_tune = np.pad(wav_speed_tune, (offset, padding - offset), \"constant\")\n",
        "    else:\n",
        "      wav_speed_tune = wav_speed_tune[:len(data)]\n",
        "\n",
        "    return wav_speed_tune\n",
        "\n",
        "  def add_noise(self, data, noise_levels=(0, 0.3)):\n",
        "    noise_level = np.random.uniform(*noise_levels)\n",
        "    noise = np.random.randn(len(data))\n",
        "    data_noise = data + noise_level * noise\n",
        "\n",
        "    return data_noise\n",
        "\n",
        "  def change_pitch(self, data):\n",
        "    n_steps = np.random.randint(-1, 2)\n",
        "    return librosa.effects.pitch_shift(data, 8000, n_steps)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "53AkvAmJhDPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataGenerator\n"
      ],
      "metadata": {
        "id": "KnWmRfauhDPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have completed all the pre - processing steps, we will define a Custom data generation Class using Keras.\n"
      ],
      "metadata": {
        "id": "UkOmSw8E1JP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather than resizing all the audio samples to have the same length by padding them with silence. The class will pad the audio and transcription based on the longest in the batch. Since padding can affect the way the networks function and can make a great deal when it comes to the performance and accuracies of our model. Sorting our data based on duration and generating each bach with small padding will allow us to minimize the downside of padding.\n",
        "\n",
        "The class returns three augmented versions for a single audio file. Since we are augmenting the audio every time rather than saving the augmented file, our data will change randomly for every batch. For instance, the speed of the audio can speed up or slow down randomly. This will considerably increase the variability in our input data.\n"
      ],
      "metadata": {
        "id": "rCGzGSSU1JP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data, sr, batch_size=32, shuffle=True):\n",
        "        self.data = data      # Data Augmentation\n",
        "        self.sr = sr\n",
        "        self.batch_size = batch_size / 4      # Data Augmentation\n",
        "        self.audio_augment = AudioAugment()\n",
        "        self.len = int(np.floor(data.shape[0]/ self.batch_size))\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __data_generation(self, batch_data):\n",
        "\n",
        "        longest_audio = int(batch_data[\"duration\"].max() * self.sr)\n",
        "        longest_trans = int(batch_data[\"char_length\"].max())\n",
        "\n",
        "        X_audio = np.zeros([int(self.batch_size * 4), longest_audio], dtype=\"float32\")\n",
        "        y_trans = np.ones([int(self.batch_size * 4), longest_trans], dtype=\"int64\")\n",
        "        X_length = np.ones([int(self.batch_size * 4), 1], dtype=\"int64\") * longest_audio\n",
        "        y_length = np.zeros([int(self.batch_size * 4), 1], dtype=\"int64\")\n",
        "\n",
        "        i = 0\n",
        "        for col, row in batch_data.iterrows():\n",
        "\n",
        "            # Add transcription\n",
        "            transcription = tf.convert_to_tensor(tokenizer.text_to_tokens(row[\"text\"], padding=True)[:, :longest_trans])\n",
        "            y_trans[i,] = y_trans[i + 1,] = y_trans[i + 2,] = y_trans[i + 3,] = transcription\n",
        "            y_length[i] = y_length[i + 1] = y_length[i + 2] = y_length[i + 3] = row[\"char_length\"]\n",
        "\n",
        "            # Add original Audio\n",
        "            audio_length = int(row[\"duration\"] * self.sr)\n",
        "            wav = np.load(row[\"path\"])[:audio_length]\n",
        "            X_audio[i, :audio_length] = wav\n",
        "            i += 1\n",
        "\n",
        "            # Add noise\n",
        "            wav_ = self.audio_augment.add_noise(wav)\n",
        "            X_audio[i, :audio_length] = wav_\n",
        "            i += 1\n",
        "\n",
        "            # Add noise\n",
        "            wav_ = self.audio_augment.add_noise(wav)\n",
        "            X_audio[i, :audio_length] = wav_\n",
        "            i += 1\n",
        "\n",
        "            # # Pitch change\n",
        "            # wav_ = self.audio_augment.change_pitch(wav)\n",
        "            # X_audio[i, :audio_length] = wav_\n",
        "            # i+=1\n",
        "\n",
        "            # Speed change\n",
        "            wav_ = self.audio_augment.change_speed(wav)\n",
        "            X_audio[i, :audio_length] = wav_\n",
        "            i += 1\n",
        "\n",
        "        outputs = {'ctc': tf.zeros(([int(self.batch_size * 4)]), dtype=tf.dtypes.float32)}\n",
        "        inputs = {\n",
        "            'the_input': tf.convert_to_tensor(X_audio),\n",
        "            'the_labels': tf.convert_to_tensor(y_trans),\n",
        "            'input_length': tf.convert_to_tensor(X_length, dtype=\"float32\"),\n",
        "            'label_length': tf.convert_to_tensor(y_length)\n",
        "        }\n",
        "        return (inputs, outputs)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "\n",
        "        self.indexes = np.arange(self.len * self.batch_size)\n",
        "\n",
        "        if self.shuffle == True:\n",
        "\n",
        "            self.indexes = self.indexes.reshape(int(self.len), int(self.batch_size))\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "            for i in range(self.len):\n",
        "                np.random.shuffle(self.indexes[i])\n",
        "\n",
        "            self.indexes = self.indexes.reshape(int(self.len * self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[int(index * self.batch_size):int((index + 1) * self.batch_size)]\n",
        "        batch_data = self.data.iloc[indexes]\n",
        "        return self.__data_generation(batch_data)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "917Vfy3LhDPl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "sr = 8000\n",
        "batch_size = 128\n",
        "sample_generator = DataGenerator(data, sr, batch_size, False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "s6wKZ51yhDPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "sample_generator.__len__()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFwJBjOihDPm",
        "outputId": "1cb0a03a-3fe3-413b-e69f-9cebf8850d64"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "source": [
        "%%time\n",
        "sample_data = sample_generator.__getitem__(261)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-9d65f72c7501>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-9d65f72c7501>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Add original Audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0maudio_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"duration\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maudio_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mX_audio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0maudio_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/AMHARIC_CLEAN/train/wav/tr_1893_tr19094.npy'"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "MsSAh-h6hDPm",
        "outputId": "827e3806-5c11-4c90-990b-8adf669c7925"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "source": [
        "sample_audios = sample_data[0][\"the_input\"]\n",
        "sample_labels = sample_data[0][\"the_labels\"]\n",
        "sample_audios_length = sample_data[0][\"input_length\"]\n",
        "sample_labels_length = sample_data[0][\"label_length\"]"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-53365dcedc86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_audios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"the_input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"the_labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_audios_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_labels_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_data' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "NuOiQWeyhDPn",
        "outputId": "f2b67055-5b80-4bf2-826e-2bc4d1b66258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "print(sample_audios.shape)\n",
        "print(sample_labels.shape)\n",
        "print(sample_audios_length.shape)\n",
        "print(sample_labels_length.shape)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-822babd0773c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_audios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_audios_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_labels_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_audios' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "0VSvTDobhDPn",
        "outputId": "f4f1b88c-4743-4f48-ad86-1b40241d36e9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "sample_labels[0]\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-92884d41181e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_labels' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "jKgrvJVJhDPo",
        "outputId": "e6800a4c-4869-45b2-91f5-55631e5239d0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "print(tokenizer.tokens_to_string(sample_labels[0].numpy()))\n",
        "audio_vis.play_audio(sample_audios[0], sr)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-ac3334f8e9b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maudio_vis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_audios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_labels' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "fwOTlTpfhDPp",
        "outputId": "797f799c-e129-48ec-8992-94ea2e1c952a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log Melgram\n"
      ],
      "metadata": {
        "id": "sZrsiNfmhDPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The spectrogram is a 2D plot between time and frequency where each point in the plot represents the amplitude of a particular frequency at a particular time in terms of intensity of color. In simple terms, the spectrogram is a spectrum(broad range of colors) of frequencies as it varies with time.\n",
        "\n",
        "A Mel Spectrogram makes two important changes relative to a regular Spectrogram that plots Frequency vs Time. It uses the Mel Scale instead of Frequency on the y - axis and It uses the Decibel Scale instead of Amplitude to indicate colors.\n",
        "\n",
        "There is an article on How to Easily Process Audio on Your GPU with TensorFlow by David Schwertfeger. The article describes how to leverage the power of the GPU to process audio data using the TensorFlow signal processor. I have used the code provided in the blog for generating Mel Spectrogram.\n"
      ],
      "metadata": {
        "id": "2zUIZA7A1JQC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "def preprocessin_model(fft_size, hop_size, n_mels, mfcc=False):\n",
        "\n",
        "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
        "    spec = LogMelgramLayer(\n",
        "        num_fft=fft_size,\n",
        "        hop_length=hop_size,\n",
        "        num_mels=n_mels,\n",
        "        sample_rate=sr,\n",
        "        f_min=0.0,\n",
        "        f_max=sr // 2,\n",
        "        eps=1e-6)(input_data)\n",
        "    x = BatchNormalization(axis=2)(spec)\n",
        "    # x = Permute((2, 1, 3), name='permute', dtype=\"float32\")(x)\n",
        "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "UFnSY7d0hDPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hop_size and  n_mels choise\n"
      ],
      "metadata": {
        "id": "Pdn6jGfQhDPt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "def compare(i, fft_size, n_mels_list, hop_size_list, sr=16000):\n",
        "\n",
        "    sample_data = sample_generator.__getitem__(i)\n",
        "    sample_audios = sample_data[0][\"the_input\"]\n",
        "    sample_labels = sample_data[0][\"the_labels\"]\n",
        "\n",
        "    nrows, ncols = len(hop_size_list), len(n_mels_list),\n",
        "    plt.figure(figsize=(4 * nrows, 4 * ncols))\n",
        "\n",
        "    for i in range(nrows):\n",
        "        n_mels = n_mels_list[i]\n",
        "\n",
        "        for y in range(ncols):\n",
        "            hop_size = hop_size_list[y]\n",
        "\n",
        "            plt.subplot(nrows, ncols, i * ncols + y + 1)\n",
        "\n",
        "            model = preprocessin_model(fft_size, hop_size, n_mels)\n",
        "            pred = model.predict(sample_audios)\n",
        "\n",
        "            pred = pred[0, :, :, 0]\n",
        "            librosa.display.specshow(pred.T, sr=sr, hop_length=hop_size, cmap=\"magma\")\n",
        "            plt.title('hop: {}, n_mels: {}, shape: {}'.format(hop_size, n_mels, pred.shape), fontsize=11)\n",
        "\n",
        "    print(\"The longest sentence in this batch has {} characters\".format(sample_labels.shape[1]))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZLinxjZbhDPu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "fft_size = 256\n",
        "n_mels_list = [256, 160, 128, 64]\n",
        "hop_size_list = [256, 160, 128, 64]\n",
        "compare(20, fft_size, n_mels_list, hop_size_list, sr)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c0511d1e54cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_mels_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhop_size_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_size_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-fffe361cd915>\u001b[0m in \u001b[0;36mcompare\u001b[0;34m(i, fft_size, n_mels_list, hop_size_list, sr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_size_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msample_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msample_audios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"the_input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msample_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"the_labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-9d65f72c7501>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-9d65f72c7501>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Add original Audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0maudio_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"duration\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maudio_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mX_audio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0maudio_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/AMHARIC_CLEAN/train/wav/tr_10251_tr099093.npy'"
          ]
        }
      ],
      "metadata": {
        "id": "ww6nHR07hDPu",
        "outputId": "0a1def7e-ff70-454d-c24e-0ba054bcb707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Choice"
      ],
      "metadata": {
        "id": "nJK01bMYhDPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "fft_size = 256\n",
        "hop_size = 128\n",
        "n_mels = 128"
      ],
      "outputs": [],
      "metadata": {
        "id": "0n87K9q9hDPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "melspecModel = preprocessin_model(fft_size, hop_size, n_mels)\n",
        "melspecModel.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"preprocessin_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, None)]            0         \n",
            "                                                                 \n",
            " log_melgram_layer (LogMelgr  (None, None, 128, 1)     0         \n",
            " amLayer)                                                        \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, None, 128, 1)     512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 512\n",
            "Trainable params: 256\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMou0zbnhDPv",
        "outputId": "b738ba51-b2f9-4b8a-e6d1-2f38618570ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "def vis(j=5):\n",
        "    for i in range(0, 330, 330 // j):\n",
        "        sample_data = sample_generator.__getitem__(i)\n",
        "        sample_audios = sample_data[0][\"the_input\"]\n",
        "        sample_labels = sample_data[0][\"the_labels\"]\n",
        "        sample_labels_length = sample_data[0][\"input_length\"]\n",
        "\n",
        "        melspec = melspecModel.predict(sample_audios)\n",
        "\n",
        "        print('\\n')\n",
        "        print('-' * 100)\n",
        "\n",
        "        print(\"The longest sentence in this batch has {} characters\".format(sample_labels.shape[1]))\n",
        "        print(\"We have to multiply the longest sentence by {} to reach length of Time steps\".format(\n",
        "            np.log2([melspec.shape[1] / sample_labels.shape[1]])[0]))\n",
        "\n",
        "        print('-' * 100)\n",
        "        print('\\n')\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(16, 4))\n",
        "        pred = melspec[0, :, :, 0]\n",
        "        vis_model(pred, \"Mel-frequency spectrogram\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "oKxSG1pjhDPw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "def vis_model(pred, title, cmap=\"magma\"):\n",
        "    librosa.display.specshow(pred.T, sr=sr, y_axis='mel', x_axis='time', hop_length=hop_size, cmap=cmap)\n",
        "    plt.title('{}. Shape = {}'.format(title, pred.shape))\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "OMedZPIWhDPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "vis(5)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-45b8f9be5c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-a82c856f470f>\u001b[0m in \u001b[0;36mvis\u001b[0;34m(j)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m330\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m330\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msample_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0msample_audios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"the_input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msample_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"the_labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-9d65f72c7501>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-9d65f72c7501>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Add original Audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0maudio_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"duration\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maudio_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mX_audio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0maudio_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/AMHARIC_CLEAN/train/wav/tr_5302_tr54003.npy'"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "S5J6Sx1lhDPx",
        "outputId": "a7916af6-5438-4fc1-ba35-53b3d350bf7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "source": [
        "melspec = melspecModel.predict(sample_audios)\n",
        "melspec.shape"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-a8e9e2e62f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmelspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmelspecModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_audios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmelspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_audios' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "mwvsT5OvhDPy",
        "outputId": "e1afdd53-8224-4dd1-8451-5e4ee24ebf1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "source": [
        "sample_audios.shape"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-7cdd62142293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_audios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_audios' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "4zHJrmM1hDPz",
        "outputId": "2606e35b-7cea-4a82-a954-ba1c3ff0ac0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINAL DATA"
      ],
      "metadata": {
        "id": "T2QuYGjBzeyO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "source": [
        "shuffled_data = shuffle(data)\n",
        "shuffled_data.head()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-23113eb4f696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshuffled_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshuffled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "zAdQX604zxln",
        "outputId": "e99b6f87-1577-489b-8fb4-ab146677c381"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "source": [
        "val_point = int(len(data)*.9)\n",
        "test_point = int(len(data)*.95)\n",
        "train_data = shuffled_data[:val_point]\n",
        "val_data = shuffled_data[val_point:test_point]\n",
        "test_data = shuffled_data[test_point:]"
      ],
      "outputs": [],
      "metadata": {
        "id": "5BwK5une0S68"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "source": [
        "train_data = train_data.sort_values(\"duration\")\n",
        "val_data = val_data.sort_values(\"duration\")\n",
        "test_data = test_data.sort_values(\"duration\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "W9Hiy7o22nZg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "source": [
        "sr = 8000\n",
        "shuffle = True\n",
        "batch_size = 32"
      ],
      "outputs": [],
      "metadata": {
        "id": "Uda5emMF1FWk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "source": [
        "train_gen = DataGenerator(train_data, sr, batch_size, shuffle)\n",
        "val_gen = DataGenerator(val_data, sr, batch_size, shuffle)\n",
        "test_gen = DataGenerator(test_data, sr, batch_size, shuffle)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yV7DpPXWzciZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "print(f\"Size of train data is {len(train_data)} and batch length is {len(train_gen)}\")\n",
        "print(f\"Size of valid data is {len(val_data)}  and batch length is {len(val_gen)}\")\n",
        "print(f\"Size of test data is {len(test_data)}  and batch length is {len(test_gen)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train data is 9606 and batch length is 1200\n",
            "Size of valid data is 534  and batch length is 66\n",
            "Size of test data is 534  and batch length is 66\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuduDhCZ19VD",
        "outputId": "c56adee3-d86d-435b-9084-381b39a73a25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CTC"
      ],
      "metadata": {
        "id": "wG-rOaJehDP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the CTC loss as the base loss function for our model. CTC is used to align the input and output sequences when the input is continuous and the output is discrete, and there are no clear element boundaries that can be used to map the input to the elements of the output sequence.\n",
        "\n",
        "The Keras CTC loss function expects y_true, y_pred, input_length, and label_length as an argument. The problem is the input length changes for each batch in our data. We can compute the input length, by dividing the length of the audio by hop size.\n",
        "\n",
        "The other point is if we are using Convolutional or Max Pooling layers in our model, we need to recompute input length since they can reduce the dimensions of the feature maps.\n",
        "\n",
        "The final point to keep in mind is the input length(number of time slices) should be greater than two times transcription length plus One. This is mentioned in the CTC paper. Apart from these points, we can calculate CTC loss just by following the documentation from Keras.\n"
      ],
      "metadata": {
        "id": "6HNDjojY1JQL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Hslsy1T7hDP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def input_lengths_lambda_func(args):\n",
        "    input_length = args\n",
        "    return tf.cast(tf.math.floor(input_length / hop_size)-1, dtype=\"float32\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "SlquxRtwhDP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = input_lengths_lambda_func(sample_audios_length[1]).numpy()\n",
        "x"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([527.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VENDrG_fhDP0",
        "outputId": "7c718c4c-c58c-4969-f95e-fc96ddf296d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def add_ctc_loss(model_builder):\n",
        "    the_labels = Input(name='the_labels', shape=(None,), dtype='float32')\n",
        "    input_lengths = Input(name='input_length', shape=(1,), dtype='float32')\n",
        "    label_lengths = Input(name='label_length', shape=(1,), dtype='float32')\n",
        "\n",
        "    input_lengths2 = Lambda(input_lengths_lambda_func)(input_lengths)\n",
        "    if model_builder.output_length:\n",
        "        output_lengths = Lambda(model_builder.output_length)(input_lengths2)\n",
        "    else:\n",
        "        output_lengths = input_lengths2\n",
        "\n",
        "    # CTC loss is implemented in a lambda layer\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')(\n",
        "        [model_builder.output, the_labels, output_lengths, label_lengths])\n",
        "    model = Model(inputs=[model_builder.input, the_labels, input_lengths, label_lengths], outputs=loss_out)\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "A5iRyPwbhDP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Builder\n"
      ],
      "metadata": {
        "id": "ZZlX4X15hDP1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def build_model(output_dim, custom_model, calc=None):\n",
        "\n",
        "    input_audios = Input(name='the_input', shape=(None,))\n",
        "    pre = melspecModel(input_audios)\n",
        "    pre.trainable = False  # Freeze the layer\n",
        "    pre = tf.squeeze(pre, [3])\n",
        "\n",
        "    y_pred = custom_model(pre)\n",
        "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
        "    model.output_length = calc\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "tW3nJDHkhDP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Trainer"
      ],
      "metadata": {
        "id": "CX_g8ub8hDP2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def train(model_builder,\n",
        "          model_name,\n",
        "          epochs,\n",
        "          verbose=1,\n",
        "          optimizer=SGD(lr=0.002, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
        "          ):\n",
        "\n",
        "    model = add_ctc_loss(model_builder)\n",
        "\n",
        "    # optimizer = Adam(lr=.01, clipnorm = 1, decay=1e-6)\n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
        "    # print(model.summary())\n",
        "\n",
        "    # add checkpointer\n",
        "    checkpointer = ModelCheckpoint(filepath=PATH_Model+model_name+'.h5', verbose=0)\n",
        "    early_stopping = EarlyStopping( monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "    # train the model\n",
        "    hist = model.fit_generator(generator=train_gen,\n",
        "                               validation_data=val_gen,\n",
        "                               epochs=epochs,\n",
        "                               callbacks=[checkpointer, early_stopping],\n",
        "                               verbose=verbose,\n",
        "                               use_multiprocessing=False)\n",
        "\n",
        "    # save model loss\n",
        "    with open(PATH_Model+model_name+'.pickle', 'wb') as f:\n",
        "        pickle.dump(hist.history, f)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "UOoeIIblhDP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Inference"
      ],
      "metadata": {
        "id": "XdbPWrohu1hM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "source": [
        "from jiwer import wer"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-9969a4e1c235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjiwer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jiwer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "metadata": {
        "id": "bODewrqNur9M",
        "outputId": "343d74a2-085f-4aba-9eae-c3333384d7d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "source": [
        "def predict(data_gen,  num_elem=1, index=0):\n",
        "    \n",
        "    pred_data = data_gen.__getitem__(index)\n",
        "\n",
        "    pred_audios = pred_data[0][\"the_input\"]\n",
        "    pred_labels = pred_data[0][\"the_labels\"]\n",
        "    pred_audios_length = pred_data[0][\"input_length\"]\n",
        "    \n",
        "    y_pred = model.predict(pred_audios)\n",
        "\n",
        "    input_shape = tf.keras.backend.shape(y_pred)\n",
        "    input_length = tf.ones(shape=input_shape[0]) * tf.keras.backend.cast(input_shape[1], 'float32')\n",
        "    prediction = tf.keras.backend.ctc_decode(y_pred, input_length, greedy=False)[0][0]\n",
        "\n",
        "\n",
        "    for i in range(0, num_elem):  # only on clean data\n",
        "        \n",
        "        pred = K.eval(prediction[i]).flatten().tolist()\n",
        "        pred = list(filter(lambda a: a != -1, pred))\n",
        "\n",
        "        ground_truth = tokenizer.tokens_to_string(pred_labels[i].numpy())\n",
        "        hypothesis   = ''.join(tokenizer.tokens_to_string(pred))\n",
        "        error        = wer(ground_truth, hypothesis)\n",
        "                \n",
        "        print('-'*48 + ' ' + str(i) + ' ' + '-'*48)\n",
        "        print('True transcription:\\n' + '\\n' + ground_truth)\n",
        "        print('-'*100)\n",
        "        print('Predicted transcription:\\n' + '\\n' + hypothesis)\n",
        "        print('-'*100)\n",
        "        print('Word Error Rate:' + str(error))\n",
        "        print('\\n')"
      ],
      "outputs": [],
      "metadata": {
        "id": "5pQ-oh4bu8Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple RNN"
      ],
      "metadata": {
        "id": "IVG_wLS6hDP1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "source": [
        "def simple_rnn_model(input_dim, output_dim=224):\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "\n",
        "    simp_rnn = GRU(output_dim, return_sequences=True, implementation=2, name='rnn')(input_data)\n",
        "\n",
        "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
        "\n",
        "    model = Model(inputs=input_data, outputs=y_pred, name=\"simple_rnn_model\")\n",
        "\n",
        "    model.output_length = lambda x: x\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "TVigDCJThDP1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "source": [
        "simple_rnn_model = simple_rnn_model(128, 224)\n",
        "# plot_model(simple_rnn_model, to_file='../img/simple_rnn_model.png')\n",
        "simple_rnn_model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"simple_rnn_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " the_input (InputLayer)      [(None, None, 128)]       0         \n",
            "                                                                 \n",
            " rnn (GRU)                   (None, None, 224)         237888    \n",
            "                                                                 \n",
            " softmax (Activation)        (None, None, 224)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 237,888\n",
            "Trainable params: 237,888\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH3CgU5AhDP1",
        "outputId": "189ab036-e6fc-46ab-f8a2-de1b42fa06d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "source": [
        "model = build_model(len(tokenizer.word_index)+2, simple_rnn_model)\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-f10aff585428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_rnn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "hg8ec8vVoYRu",
        "outputId": "3c5c8cac-206d-4981-f378-9f34944b99e8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "source": [
        "# import mlflow\n",
        "# mlflow.set_experiment('speech_recognition')\n",
        "# mlflow.tensorflow.autolog()\n",
        "train(model_builder=model, model_name=\"SimpleRNN_model\", epochs=10)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-ecfefb33a8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# mlflow.set_experiment('speech_recognition')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# mlflow.tensorflow.autolog()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_builder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SimpleRNN_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "nq2-tGhkoRPE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "707cb850-b5a4-4fc4-dc49-f9825de58389"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "source": [
        "x = predict(test_gen, 1, 0)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-1a35d5087410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-0fa13dbe179d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(data_gen, num_elem, index)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnum_elem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpred_audios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"the_input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-9d65f72c7501>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-9d65f72c7501>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Add original Audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0maudio_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"duration\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maudio_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mX_audio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0maudio_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/AMHARIC_CLEAN/train/wav/tr_7930_tr80031.npy'"
          ]
        }
      ],
      "metadata": {
        "id": "EcUozbQIvOya",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "9dcc95d6-d678-4581-808b-b56e62b79086"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONV_BRNN"
      ],
      "metadata": {
        "id": "ZLxu_CXisYTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$floor(\\frac{n-f+2p}{s}+1) $"
      ],
      "metadata": {
        "id": "yREqsWcetgZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "source": [
        "def cnn_output_length(input_length, kernel_list, pool_sizes, cnn_stride, mx_stride, padding='valid'):\n",
        "\n",
        "    if padding == 'same':\n",
        "        output_length = input_length\n",
        "        \n",
        "        return output_length\n",
        "\n",
        "    elif padding == 'valid':\n",
        "\n",
        "        output_length = input_length\n",
        "        for i, j, k in zip(kernel_list, pool_sizes, mx_stride):\n",
        "            output_length = (output_length - i)/cnn_stride + 1\n",
        "            if j != 0: output_length = (output_length - j)/k + 1\n",
        "        \n",
        "        return tf.math.floor(output_length)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GHOS_l1tskuE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "source": [
        "def CONV_BRNN( input_dim, filters, kernels, pool_sizes, mx_stride, cnn_stride, output_dim=224, num_cnn = 3, num_birnn = 4 ):\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    x = Reshape((-1, input_dim, 1), dtype=\"float32\")(input_data)\n",
        "    \n",
        "    for i in range(num_cnn):\n",
        "        x = Conv2D(filters=filters[i], kernel_size=kernels[i], strides=1, padding='valid', name='cnn_{}'.format(i))(x)\n",
        "        x = LeakyReLU(.1)(x)\n",
        "        x = MaxPooling2D( pool_size=pool_sizes[i], strides=(1,2), padding=\"valid\")(x)\n",
        "        x = BatchNormalization(name='bn_cnn_{}'.format(i))(x)\n",
        "        \n",
        "    x = Reshape((-1, x.shape[-1] * x.shape[-2] ))(x)\n",
        "\n",
        "    for i in range(num_birnn):\n",
        "        x = Bidirectional(GRU(units=512, return_sequences=True, implementation=2, name='rnn_{}'.format(i)))(x)\n",
        "        x = LeakyReLU(.1)(x)\n",
        "        x = BatchNormalization(name='bn_rnn_{}'.format(i))(x)\n",
        "  \n",
        "    x = TimeDistributed(Dense(output_dim))(x)\n",
        "\n",
        "    y_pred = Activation('softmax', name='softmax')(x)\n",
        "\n",
        "    model = Model( inputs=input_data, outputs=y_pred, name=\"CONV_BRNN\" )\n",
        "\n",
        "    output_length_calculater = lambda x: cnn_output_length(x, kernels, pool_sizes, cnn_stride, mx_stride)\n",
        "    \n",
        "    return model, output_length_calculater"
      ],
      "outputs": [],
      "metadata": {
        "id": "jdLp79F6sYzT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "source": [
        "filters = [16, 32, 64]\n",
        "kernels = [7, 5, 3] \n",
        "pool_sizes = [3, 3, 3]  \n",
        "mx_stride = [1, 1, 2]\n",
        "cnn_stride = 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "v1RZCsZvqg4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "source": [
        "CONV_BRNN_Model, calc = CONV_BRNN(n_mels, filters, kernels, pool_sizes, mx_stride, cnn_stride,)\n",
        "plot_model(CONV_BRNN_Model, to_file=PATH_Model+'CONV_BRNN_Model.png')\n",
        "CONV_BRNN_Model.summary()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-dd9faf5c61e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCONV_BRNN_Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONV_BRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_stride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONV_BRNN_Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_Model\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'CONV_BRNN_Model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mCONV_BRNN_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m   \u001b[0;31m# Save image to disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m   \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m   \u001b[0;31m# Return the image as a Jupyter Image object, to be displayed in-line.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;31m# Note that we cannot easily detect whether the code is running in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydot_ng/__init__.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, path, prog, format)\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m         \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1756\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pydot_ng/__init__.py\u001b[0m in \u001b[0;36mget_fobj\u001b[0;34m(fname, mode)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \"\"\"\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Models/CONV_BRNN_Model.png'"
          ]
        }
      ],
      "metadata": {
        "id": "UAh4dFgLtuaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "6cfed584-3f23-40e1-b8ca-1c1e601175fe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = build_model(len(tokenizer.word_index)+2, CONV_BRNN_Model, calc)\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "BCsRrMz2hDP2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train(model_builder=model, model_name=\"CONV_BRNN_Model\", epochs=10)"
      ],
      "outputs": [],
      "metadata": {
        "id": "npl8bLjehDP4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = predict(test_gen, 5, 0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "lrltV--4vWEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESNET"
      ],
      "metadata": {
        "id": "uqMVe-Heg8zX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "source": [
        "def cnn_output_length(input_length, kernel_list, pool_sizes, cnn_stride, mx_stride, padding='same'):\n",
        "\n",
        "    if padding == 'same':        \n",
        "        output_length = input_length\n",
        "        for i, j in zip(cnn_stride, pool_sizes):\n",
        "            output_length = (output_length)/i\n",
        "            if j != 0: output_length = (output_length - j)/mx_stride + 1\n",
        "                \n",
        "        return tf.math.ceil(output_length)\n",
        "\n",
        "    elif padding == 'valid':\n",
        "\n",
        "        output_length = input_length\n",
        "        for i, j in zip(kernel_list, pool_sizes):\n",
        "            output_length = (output_length - i)/cnn_stride + 1\n",
        "            if j != 0: output_length = (output_length - j)/mx_stride + 1\n",
        "        \n",
        "        return tf.math.floor(output_length)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fMQcleHdg8zX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "source": [
        "def block(filters, inp):\n",
        "    x = BatchNormalization()(inp)\n",
        "    x = LeakyReLU(.1)(x)\n",
        "    x = Dropout(.4)(x)\n",
        "    x = Conv2D(filters, (3,3), padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(.1)(x)\n",
        "    x = Dropout(.4)(x)\n",
        "    x = Conv2D(filters, (3,3), padding = 'same')(x)\n",
        "    return(x)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZMUI1juig8zX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "source": [
        "def resnet( input_dim, output_dim=224, units=256,  num_birnn=2):\n",
        "\n",
        "    filters = [32, 32, 32]   \n",
        "    kernels = [3, 3, 3] \n",
        "    pool_sizes = [0, 0, 2]  \n",
        "    cnn_stride = [1, 1, 1]\n",
        "    mx_stride = 2\n",
        "\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    x = Reshape((-1, input_dim, 1), dtype=\"float32\")(input_data)\n",
        "    \n",
        "    x = Conv2D(filters[0], (3,3), padding = 'same')(x)\n",
        "    x = MaxPooling2D((1,2), strides=(1, 2), padding = 'same')(x)\n",
        "\n",
        "    x = Add()([block(filters[0], x),x])  \n",
        "    x = Add()([block(filters[0], x),x])\n",
        "    x = Add()([block(filters[0], x),x])\n",
        "\n",
        "    x = Conv2D(filters[1], (3,3), padding = 'same')(x)\n",
        "    x = MaxPooling2D((1,2), strides=(1, 2), padding = 'same')(x)\n",
        "    \n",
        "    x = Add()([block(filters[1], x),x])\n",
        "    x = Add()([block(filters[1], x),x])\n",
        "    x = Add()([block(filters[1], x),x])\n",
        "    \n",
        "    x = Conv2D(filters[2], (3,3), padding = 'same')(x)\n",
        "    x = MaxPooling2D((1,2), strides=(1, 2), padding = 'same')(x)\n",
        "\n",
        "    x = Add()([block(filters[2], x),x])  \n",
        "    x = Add()([block(filters[2], x),x])\n",
        "    x = Add()([block(filters[2], x),x])\n",
        "\n",
        "    # x = MaxPooling2D((2,2), strides=2, padding = 'same')(x)\n",
        "    x = AveragePooling2D((2, 2), strides=2, padding='same')(x)\n",
        "    x = Reshape((-1, x.shape[-1] * x.shape[-2] ))(x)\n",
        "\n",
        "    # GRULayer\n",
        "    for i in range(num_birnn):\n",
        "        x = Bidirectional(GRU(units=units, return_sequences=True, implementation=2, name='rnn_{}'.format(i)))(x)\n",
        "        x = Dropout(.4)(x)\n",
        "        x = LeakyReLU(.1)(x)\n",
        "        x = BatchNormalization(name='bn_rnn_{}'.format(i))(x)\n",
        "\n",
        "    x = TimeDistributed(Dense(output_dim))(x)\n",
        "    y_pred = Activation('softmax', name='softmax')(x)\n",
        "\n",
        "    model = Model( inputs=input_data, outputs=y_pred, name=\"custom_model\" )\n",
        "\n",
        "    output_length_calculater = lambda x: cnn_output_length(x, kernels, pool_sizes, cnn_stride, mx_stride)\n",
        "    \n",
        "    return model, output_length_calculater"
      ],
      "outputs": [],
      "metadata": {
        "id": "9SN7Cycw-CuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "source": [
        "resnet, calc = resnet(n_mels, 224, 512, 4)\n",
        "# plot_model(resnet, to_file='/content/drive/MyDrive/resnet.png')\n",
        "resnet.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"custom_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " the_input (InputLayer)         [(None, None, 128)]  0           []                               \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, None, 128, 1  0           ['the_input[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, None, 128, 3  320         ['reshape_2[0][0]']              \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, None, 64, 32  0          ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, None, 64, 32  128        ['max_pooling2d_3[0][0]']        \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, None, 64, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 64, 32  0           ['leaky_re_lu_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, None, 64, 32  9248        ['dropout[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, None, 64, 32  128        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, None, 64, 32  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 64, 32  0           ['leaky_re_lu_8[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, None, 64, 32  9248        ['dropout_1[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, None, 64, 32  0           ['conv2d_2[0][0]',               \n",
            "                                )                                 'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, None, 64, 32  128        ['add[0][0]']                    \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, None, 64, 32  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, None, 64, 32  0           ['leaky_re_lu_9[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, None, 64, 32  9248        ['dropout_2[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, None, 64, 32  128        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, None, 64, 32  0           ['batch_normalization_4[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, None, 64, 32  0           ['leaky_re_lu_10[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, None, 64, 32  9248        ['dropout_3[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, None, 64, 32  0           ['conv2d_4[0][0]',               \n",
            "                                )                                 'add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, None, 64, 32  128        ['add_1[0][0]']                  \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, None, 64, 32  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, None, 64, 32  0           ['leaky_re_lu_11[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, None, 64, 32  9248        ['dropout_4[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, None, 64, 32  128        ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, None, 64, 32  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, None, 64, 32  0           ['leaky_re_lu_12[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, None, 64, 32  9248        ['dropout_5[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, None, 64, 32  0           ['conv2d_6[0][0]',               \n",
            "                                )                                 'add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, None, 64, 32  9248        ['add_2[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, None, 32, 32  0          ['conv2d_7[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, None, 32, 32  128        ['max_pooling2d_4[0][0]']        \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)     (None, None, 32, 32  0           ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, None, 32, 32  0           ['leaky_re_lu_13[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, None, 32, 32  9248        ['dropout_6[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, None, 32, 32  128        ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_14 (LeakyReLU)     (None, None, 32, 32  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, None, 32, 32  0           ['leaky_re_lu_14[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, None, 32, 32  9248        ['dropout_7[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, None, 32, 32  0           ['conv2d_9[0][0]',               \n",
            "                                )                                 'max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, None, 32, 32  128        ['add_3[0][0]']                  \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_15 (LeakyReLU)     (None, None, 32, 32  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, None, 32, 32  0           ['leaky_re_lu_15[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, None, 32, 32  9248        ['dropout_8[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, None, 32, 32  128        ['conv2d_10[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_16 (LeakyReLU)     (None, None, 32, 32  0           ['batch_normalization_10[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, None, 32, 32  0           ['leaky_re_lu_16[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, None, 32, 32  9248        ['dropout_9[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, None, 32, 32  0           ['conv2d_11[0][0]',              \n",
            "                                )                                 'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, None, 32, 32  128        ['add_4[0][0]']                  \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_17 (LeakyReLU)     (None, None, 32, 32  0           ['batch_normalization_11[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, None, 32, 32  0           ['leaky_re_lu_17[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, None, 32, 32  9248        ['dropout_10[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, None, 32, 32  128        ['conv2d_12[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, None, 32, 32  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, None, 32, 32  0           ['leaky_re_lu_18[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, None, 32, 32  9248        ['dropout_11[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, None, 32, 32  0           ['conv2d_13[0][0]',              \n",
            "                                )                                 'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, None, 32, 32  9248        ['add_5[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, None, 16, 32  0          ['conv2d_14[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, None, 16, 32  128        ['max_pooling2d_5[0][0]']        \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, None, 16, 32  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, None, 16, 32  0           ['leaky_re_lu_19[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, None, 16, 32  9248        ['dropout_12[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, None, 16, 32  128        ['conv2d_15[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, None, 16, 32  0           ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, None, 16, 32  0           ['leaky_re_lu_20[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, None, 16, 32  9248        ['dropout_13[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, None, 16, 32  0           ['conv2d_16[0][0]',              \n",
            "                                )                                 'max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, None, 16, 32  128        ['add_6[0][0]']                  \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, None, 16, 32  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, None, 16, 32  0           ['leaky_re_lu_21[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, None, 16, 32  9248        ['dropout_14[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, None, 16, 32  128        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, None, 16, 32  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, None, 16, 32  0           ['leaky_re_lu_22[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, None, 16, 32  9248        ['dropout_15[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, None, 16, 32  0           ['conv2d_18[0][0]',              \n",
            "                                )                                 'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, None, 16, 32  128        ['add_7[0][0]']                  \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_23 (LeakyReLU)     (None, None, 16, 32  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, None, 16, 32  0           ['leaky_re_lu_23[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, None, 16, 32  9248        ['dropout_16[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, None, 16, 32  128        ['conv2d_19[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_24 (LeakyReLU)     (None, None, 16, 32  0           ['batch_normalization_18[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, None, 16, 32  0           ['leaky_re_lu_24[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, None, 16, 32  9248        ['dropout_17[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, None, 16, 32  0           ['conv2d_20[0][0]',              \n",
            "                                )                                 'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, None, 8, 32)  0          ['add_8[0][0]']                  \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, None, 256)    0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, None, 1024)  2365440     ['reshape_3[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, None, 1024)   0           ['bidirectional_4[0][0]']        \n",
            "                                                                                                  \n",
            " leaky_re_lu_25 (LeakyReLU)     (None, None, 1024)   0           ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " bn_rnn_0 (BatchNormalization)  (None, None, 1024)   4096        ['leaky_re_lu_25[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirectional  (None, None, 1024)  4724736     ['bn_rnn_0[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, None, 1024)   0           ['bidirectional_5[0][0]']        \n",
            "                                                                                                  \n",
            " leaky_re_lu_26 (LeakyReLU)     (None, None, 1024)   0           ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            " bn_rnn_1 (BatchNormalization)  (None, None, 1024)   4096        ['leaky_re_lu_26[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional_6 (Bidirectional  (None, None, 1024)  4724736     ['bn_rnn_1[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, None, 1024)   0           ['bidirectional_6[0][0]']        \n",
            "                                                                                                  \n",
            " leaky_re_lu_27 (LeakyReLU)     (None, None, 1024)   0           ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " bn_rnn_2 (BatchNormalization)  (None, None, 1024)   4096        ['leaky_re_lu_27[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional_7 (Bidirectional  (None, None, 1024)  4724736     ['bn_rnn_2[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, None, 1024)   0           ['bidirectional_7[0][0]']        \n",
            "                                                                                                  \n",
            " leaky_re_lu_28 (LeakyReLU)     (None, None, 1024)   0           ['dropout_21[0][0]']             \n",
            "                                                                                                  \n",
            " bn_rnn_3 (BatchNormalization)  (None, None, 1024)   4096        ['leaky_re_lu_28[0][0]']         \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, None, 224)   229600      ['bn_rnn_3[0][0]']               \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " softmax (Activation)           (None, None, 224)    0           ['time_distributed_1[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,973,216\n",
            "Trainable params: 16,963,872\n",
            "Non-trainable params: 9,344\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oD5LeZw-CZ7",
        "outputId": "f2f97a70-e691-4d9b-cca8-3ec6e1ab6247"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "source": [
        "model = build_model(len(tokenizer.word_index)+2, resnet, calc)\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-287acae827c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "_2TRtboFWoHr",
        "outputId": "8d03a7a8-5d0d-49f6-dced-33e96ba1e8b0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "source": [
        "# mlflow.set_experiment('Tensorflow')\n",
        "# mlflow.tensorflow.autolog()\n",
        "train(model_builder=model, model_name=\"resnet_Model\", epochs=25)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-a83336509cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mlflow.set_experiment('Tensorflow')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# mlflow.tensorflow.autolog()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_builder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"resnet_Model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "jjqkQ-3wWoHs",
        "outputId": "bf647451-f52b-4afa-fca0-4f57d37ac124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "source": [
        "file = open(\"/content/resnet_Model.pickle\",'rb')\n",
        "object_file = pickle.load(file)\n",
        "file.close()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-f6bdf6fe600e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/resnet_Model.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mobject_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/resnet_Model.pickle'"
          ]
        }
      ],
      "metadata": {
        "id": "L3uAjg60gxff",
        "outputId": "8168cf2a-1f58-4b91-b865-d2a3abe22f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "source": [
        "  def plot_history(history):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(history['loss'], label=\"loss\")\n",
        "    plt.plot(history['val_loss'], label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    # time = strftime(\"%Y-%m-%d-%H:%M\", gmtime())\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Us_uWBtlhI2F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "source": [
        "plot_history(object_file)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-9abcbd1498fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'object_file' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "vF8XOMSqhNKU",
        "outputId": "73f88685-660c-466e-e781-e620d6e585c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train(model_builder=model, model_name=\"resnet_new\", epochs=50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1200/1200 [==============================] - 738s 609ms/step - loss: 14.9248 - val_loss: 24.9730\n",
            "Epoch 2/50\n",
            "1200/1200 [==============================] - 732s 609ms/step - loss: 14.8936 - val_loss: 25.7370\n",
            "Epoch 3/50\n",
            "1200/1200 [==============================] - 735s 612ms/step - loss: 14.6069 - val_loss: 25.9315\n",
            "Epoch 4/50\n",
            "1200/1200 [==============================] - 722s 601ms/step - loss: 13.9830 - val_loss: 26.1137\n",
            "Epoch 5/50\n",
            "1200/1200 [==============================] - 720s 600ms/step - loss: 13.3778 - val_loss: 25.9429\n",
            "Epoch 6/50\n",
            "1200/1200 [==============================] - 727s 606ms/step - loss: 12.9830 - val_loss: 27.0448\n",
            "Epoch 7/50\n",
            "1200/1200 [==============================] - 726s 605ms/step - loss: 12.1761 - val_loss: 25.5905\n",
            "Epoch 8/50\n",
            "1200/1200 [==============================] - 735s 612ms/step - loss: 12.1303 - val_loss: 26.4370\n",
            "Epoch 9/50\n",
            "1200/1200 [==============================] - 732s 610ms/step - loss: 11.7117 - val_loss: 26.4420\n",
            "Epoch 10/50\n",
            "1200/1200 [==============================] - 733s 611ms/step - loss: 11.8934 - val_loss: 26.8221\n",
            "Epoch 11/50\n",
            "1200/1200 [==============================] - 733s 610ms/step - loss: 11.1040 - val_loss: 26.2683\n"
          ]
        }
      ],
      "metadata": {
        "id": "JRqnBWHCWoHu",
        "outputId": "0ab7970b-1666-4d59-a80c-9e077d9ad5c6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "opt = SGD(lr=0.0005, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "train(model_builder=model, model_name=\"resnet_v3\", epochs=50, optimizer=opt)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1200/1200 [==============================] - 742s 609ms/step - loss: 12.8161 - val_loss: 24.0373\n",
            "Epoch 2/50\n",
            "1200/1200 [==============================] - 738s 614ms/step - loss: 10.8825 - val_loss: 23.9008\n",
            "Epoch 3/50\n",
            "1200/1200 [==============================] - 736s 613ms/step - loss: 10.9055 - val_loss: 24.2030\n",
            "Epoch 4/50\n",
            "1200/1200 [==============================] - 734s 611ms/step - loss: 10.5747 - val_loss: 24.4141\n",
            "Epoch 5/50\n",
            "1200/1200 [==============================] - 740s 616ms/step - loss: 10.4964 - val_loss: 23.9909\n",
            "Epoch 6/50\n",
            "1200/1200 [==============================] - 723s 602ms/step - loss: 10.0709 - val_loss: 24.5373\n",
            "Epoch 7/50\n",
            "1200/1200 [==============================] - 734s 611ms/step - loss: 9.8915 - val_loss: 24.2895\n",
            "Epoch 8/50\n",
            "1200/1200 [==============================] - 735s 612ms/step - loss: 10.0206 - val_loss: 24.2571\n",
            "Epoch 9/50\n",
            "1200/1200 [==============================] - 744s 619ms/step - loss: 9.8068 - val_loss: 24.7826\n",
            "Epoch 10/50\n",
            "1200/1200 [==============================] - 733s 610ms/step - loss: 9.4582 - val_loss: 24.4488\n",
            "Epoch 11/50\n",
            "1200/1200 [==============================] - 730s 609ms/step - loss: 9.1321 - val_loss: 24.3031\n",
            "Epoch 12/50\n",
            "1200/1200 [==============================] - 743s 619ms/step - loss: 8.9534 - val_loss: 25.7153\n"
          ]
        }
      ],
      "metadata": {
        "id": "OgsRMlVrWoHu",
        "outputId": "5a536a17-e947-41e3-8633-593e6aacb2ec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_name = \"resnet_v3\"\n",
        "model.load_weights(PATH_Model + model_name + '.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "rPVU2m_nWoHv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = predict(test_gen, 20, 3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------ 0 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "የመንግስት ጋዜጠኛው ኢህአዴግን በዘረኝነት ከሰሰ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "የመንግስት ጋዜጠኛው ኢህአደግን በዘረኝነት ከሶስ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.4\n",
            "\n",
            "\n",
            "------------------------------------------------ 4 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "ቤዛ ጐረ መሰ መሰለኝ ትእዛዝ አልቀበልም አለ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "ቤዛ ጐረ መሰ መሰለኝ ትእዛዝ አልቀበልም አለ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.0\n",
            "\n",
            "\n",
            "------------------------------------------------ 8 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "በእለቱ ኢንተር አንድ ለዜሮ አሸን ፏል\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "በእለቱ ኢንተር አንድ ለዜሮ አሸን ፏል\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.0\n",
            "\n",
            "\n",
            "------------------------------------------------ 12 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "ኢትዮጵያውያን በዋሽንግተን ዲሲ አሜሪካን የሚያወግዝ ሰልፍ አደረጉ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "ኢትዮጵያውያን በዋሽንግተን ዲሲ አሜሪካን የሚዋግ ሰልፍ አደረጉ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.14285714285714285\n",
            "\n",
            "\n",
            "------------------------------------------------ 16 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "አንዳንዶቹም የብሄራዊ ውትድርና ስልጠና የወሰዱ ናቸው\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "አንዳንዶቹም የብሄራዊ ትድርና ስልጠና ወሰዱ ናቸው\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.3333333333333333\n",
            "\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "id": "GxKrhHmsWoHv",
        "outputId": "cbd19eaa-36ae-4e88-b08b-c170b8a57534"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = predict(test_gen, 20, 4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------ 0 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "ለምን ኢትዮጵያ ውጊያውን ማጠናከር እንዳለባት ከላይ የተሰጡት ምክንያቶች አጠቃላይ ሁኔታውን የገመገሙ ናቸው\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "ለምን ኢትዮጵያ ውጊያውን ማጠናከር እንዳለባት ከላይ የተሰጡት ምክንያቶች አጠቃላይ ሁኔታውን የገመገሙ ናቸው\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.0\n",
            "\n",
            "\n",
            "------------------------------------------------ 4 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "እንደ ቢሮው መግለጫ ግንባታቸው የተጠናቀቀ ፕሮጄክቶች በግንባታ ላይ ካሉት አንድመቶ አስራስምንት ፕሮጄክቶች መካከል የሚጠቀሱ ናቸው\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "እንደቢሮ መግለጫ ግንባታቸው የተጠናቀ ፕሮጀክቶች በግንባታ ላይ ካሉት አንድመቶ አስራስምንት ፕሮጀክቶች መካከል የሚጠቀሱ ናቸው\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.3333333333333333\n",
            "\n",
            "\n",
            "------------------------------------------------ 8 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "ኢትዮጵያ ካገኘችው ሜዳሊያ ጋር እና ከህዝቧ ብዛት ጋር ሲነጻጸር ከፍተኛውን እና እውነተኛውን የ አሸነ ፊነት ደረጃ በሁለተኝነት መቀዳጀቷ ን ገልጿ ል\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "ኢትዮጵያ ካገኘቹ ሜየዳሊያ ጋር እና ከህዝቡ ብዛት ጋር ሲሚጻጸር ከፍተኛውና እውንተኛውን ያሸናፊነት ደረጃ በሁለተኝነት መቀዳጀቷ ን ገልጿ ል\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.47619047619047616\n",
            "\n",
            "\n",
            "------------------------------------------------ 12 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "የተላለፈው ውሳኔ ኢትዮጵያ ሉአላዊነቷን ለማስከበር የምትወስደውን እርምጃ እንደሚያ ደናቅፍ ና ፍትሀዊ እንዳልሆነ ሌሎች ዲፕሎማቶችም ይገልጻሉ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "የተላለፈው ውሳኔ ኢትዮጵያ ለዋላይነቷን ለማስከበር የምትወስደውን እርምጃ እንደሚያደናቅፍና ፍታዊ እንዳልሆነ ሌሎች ዲፕሎማቶችም ይገልጻሉ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.3333333333333333\n",
            "\n",
            "\n",
            "------------------------------------------------ 16 ------------------------------------------------\n",
            "True transcription:\n",
            "\n",
            "እንግዲህ ልብ ይበሉ ለእንግሊዟ ንግስት በጻፉት ደብዳቤ ላይየ አጼ ቴዎድሮስን ሞት ምስራች በመስማታቸው መደሰታቸውን ገልጸዋል\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Predicted transcription:\n",
            "\n",
            "እንግዲህ ልብ ይበሉ ለእንግሊዟ ንግስት በጻፉት ደብዳቤ ላይየ አጼ ቴዎድሮስን ሞት ምስራች በመስማታቸው መደሰታቸውን ገልጸዋል\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate:0.0\n",
            "\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "id": "pF8VU80fWoHw",
        "outputId": "b3019a9d-dc41-4be2-bd43-86da9bdcaa51"
      }
    }
  ]
}